{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from StereoNet_single import StereoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDisparityMap(left, right, algo = \"bm\"):\n",
    "    # OpenCV disparity filtering\n",
    "    # algo: stereo matching method (bm or sgbm)\n",
    "    \n",
    "    no_downscale = True\n",
    "    max_disp = 128\n",
    "    sigma = 1.5\n",
    "    lmbda = 8000.0\n",
    "    vis_mult = 1 # coefficient used to scale disparity map visualizations\n",
    "\n",
    "    wsize = 17 # default window size for BM on full-sized views\n",
    "    if algo==\"sgbm\":\n",
    "        wsize = 3; # default window size for SGBM\n",
    "    #elif not no_downscale and algo==\"bm\" and filter==\"wls_conf\":\n",
    "     #   wsize = 7; # default window size for BM on downscaled views (downscaling is performed only for wls_conf)\n",
    "\n",
    "    left_for_matcher = None\n",
    "    right_for_matcher = None\n",
    "    left_disp = None\n",
    "    right_disp = None\n",
    "    wls_filter = None\n",
    "\n",
    "    if not no_downscale:\n",
    "        ## downscale the views to speed-up the matching stage, as we will need to compute both left\n",
    "        ## and right disparity maps for confidence map computation\n",
    "        ## [downscale]\n",
    "        max_disp/=2;\n",
    "        if (max_disp%16) != 0:\n",
    "            max_disp += 16-(max_disp%16);\n",
    "\n",
    "        max_disp = int(max_disp)\n",
    "\n",
    "        # @TODO: Resizing is not, correct it\n",
    "#         scale_percent = 60 # percent of original size\n",
    "#         width = int(img.shape[1] * scale_percent / 100)\n",
    "#         height = int(img.shape[0] * scale_percent / 100)\n",
    "\n",
    "#         left_for_matcher = cv2.resize(left, None, fx=0.5 , fy=0.5, interpolation=cv2.INTER_LINEAR_EXACT);\n",
    "#         right_for_matcher = cv2.resize(right, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR_EXACT);\n",
    "\n",
    "    else:\n",
    "        left_for_matcher = ir1_image.copy()\n",
    "        right_for_matcher = ir2_image.copy()\n",
    "\n",
    "#         print('Size of left_for_matcher frame: ', left_for_matcher.shape)\n",
    "#         print('Size of right_for_matcher frame: ', right_for_matcher.shape)\n",
    "\n",
    "    if algo==\"bm\":\n",
    "        left_matcher = cv2.StereoBM_create(max_disp, wsize);\n",
    "        wls_filter = cv2.ximgproc.createDisparityWLSFilter(left_matcher);\n",
    "        right_matcher = cv2.ximgproc.createRightMatcher(left_matcher);\n",
    "\n",
    "        ## Don't need to convert to GRAY as we are already using IR images (1-channel)\n",
    "        # cvtColor(left_for_matcher,  left_for_matcher,  COLOR_BGR2GRAY);\n",
    "        # cvtColor(right_for_matcher, right_for_matcher, COLOR_BGR2GRAY);\n",
    "\n",
    "        ## Matching\n",
    "        # matching_time = (double)getTickCount();\n",
    "        left_disp = left_matcher.compute(left_for_matcher, right_for_matcher);\n",
    "        right_disp = right_matcher.compute(right_for_matcher,left_for_matcher);\n",
    "        # matching_time = ((double)getTickCount() - matching_time)/getTickFrequency(); \n",
    "    elif algo==\"sgbm\":\n",
    "        left_matcher  = cv2.StereoSGBM_create(max_disp,wsize);\n",
    "        left_matcher.setP1(24*wsize*wsize);\n",
    "        left_matcher.setP2(96*wsize*wsize);\n",
    "        left_matcher.setPreFilterCap(63);\n",
    "        left_matcher.setMode(cv2.StereoSGBM_MODE_SGBM_3WAY);\n",
    "        wls_filter = cv2.ximgproc.createDisparityWLSFilter(left_matcher);\n",
    "        right_matcher = cv2.ximgproc.createRightMatcher(left_matcher);\n",
    "\n",
    "        # matching_time = (double)getTickCount();\n",
    "        left_disp = left_matcher.compute(left_for_matcher, right_for_matcher);\n",
    "        right_disp = right_matcher.compute(right_for_matcher,left_for_matcher);\n",
    "        # matching_time = ((double)getTickCount() - matching_time)/getTickFrequency();\n",
    "\n",
    "    ## Filtering\n",
    "    wls_filter.setLambda(lmbda);\n",
    "    wls_filter.setSigmaColor(sigma);\n",
    "    # filtering_time = (double)getTickCount();\n",
    "    filtered_disp = wls_filter.filter(left_disp, left, disparity_map_right=right_disp);\n",
    "    # filtering_time = ((double)getTickCount() - filtering_time)/getTickFrequency();\n",
    "\n",
    "    raw_disparity = left_disp\n",
    "    filtered_disparity = filtered_disp\n",
    "    \n",
    "    conf_map = wls_filter.getConfidenceMap();\n",
    "    ROI = wls_filter.getROI();\n",
    "    \n",
    "    return raw_disparity, filtered_disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length = 643.33 #942.8       # lense focal length, 1.88mm, 942.8 ???\n",
    "baseline = 55   #49.75  distance in mm between the two cameras\n",
    "units = 0.512     # depth units, adjusted for the output to fit in one byte\n",
    "\n",
    "def convertDisparityMapToDepthMap(disparityMap):\n",
    "    # shape: disparityMap.shape\n",
    "    valid_pixels = disparityMap > 0\n",
    "    depth = np.zeros(shape=disparityMap.shape).astype(\"uint8\")\n",
    "    depth[valid_pixels] = (focal_length * baseline) / (units * disparityMap[valid_pixels])\n",
    "    \n",
    "    return depth, valid_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereoNetModel = StereoNet(k=4-1, r=4-1, maxdisp=192)\n",
    "stereoNetModel = nn.DataParallel(stereoNetModel)\n",
    "stereoNetModel.eval();\n",
    "\n",
    "def getStereoNet(left, right):\n",
    "    normalize = {'mean': [0.0, 0.0, 0.0], 'std': [1.0, 1.0, 1.0]}\n",
    "    m = left.shape[0] # 480\n",
    "    n = right.shape[1] # 640\n",
    "    imgL = np.zeros((m, n, 3))\n",
    "    imgL[:,:,0] = left\n",
    "    imgL[:,:,1] = left\n",
    "    imgL[:,:,2] = left\n",
    "    imgL = imgL.astype(float)\n",
    "\n",
    "    imgR = np.zeros((m, n, 3))\n",
    "    imgR[:,:,0] = right\n",
    "    imgR[:,:,1] = right\n",
    "    imgR[:,:,2] = right\n",
    "    imgR = imgR.astype(float)\n",
    "\n",
    "#         print (ir1_image.shape)\n",
    "#         print (imgL.shape)\n",
    "#         neighbour = torch.tensor(neighbour).float().unsqueeze(0)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(**normalize)\n",
    "    ])\n",
    "\n",
    "    imgL = transform(imgL).float()\n",
    "    imgR = transform(imgR).float()\n",
    "\n",
    "    outputs = None\n",
    "    with torch.no_grad():\n",
    "        imgL1 = imgL.unsqueeze(0)\n",
    "        imgR1 = imgR.unsqueeze(0)\n",
    "        outputs = stereoNetModel(imgL1, imgR1)\n",
    "\n",
    "#         print('model output')\n",
    "#         print(len(outputs))\n",
    "\n",
    "    sn_disparity = outputs[0].squeeze(0).cpu().numpy()\n",
    "    sn_disparity_refined = outputs[1].squeeze(0).cpu().numpy()\n",
    "    # convert to depth map\n",
    "    sn_depth_map, sn_valid_pixels = convertDisparityMapToDepthMap(sn_disparity_refined)\n",
    "\n",
    "    return sn_depth_map, sn_disparity_refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laser power =  150.0\n",
      "laser power range =  0.0 ~ 360.0\n"
     ]
    }
   ],
   "source": [
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "res_x = 640\n",
    "res_y = 480\n",
    "\n",
    "config.enable_stream(rs.stream.depth, res_x, res_y, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, res_x, res_y, rs.format.bgr8, 30)\n",
    "\n",
    "config.enable_stream(rs.stream.infrared, 1, res_x, res_y, rs.format.y8, 30)\n",
    "config.enable_stream(rs.stream.infrared, 2, res_x, res_y, rs.format.y8, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline_profile = pipeline.start(config)\n",
    "\n",
    "## To set laser on/off or set laser power\n",
    "device = pipeline_profile.get_device()\n",
    "depth_sensor = device.query_sensors()[0]\n",
    "laser_pwr = depth_sensor.get_option(rs.option.laser_power)\n",
    "print(\"laser power = \", laser_pwr)\n",
    "laser_range = depth_sensor.get_option_range(rs.option.laser_power)\n",
    "print(\"laser power range = \" , laser_range.min , \"~\", laser_range.max)\n",
    "depth_sensor.set_option(rs.option.laser_power, 0)\n",
    "\n",
    "\n",
    "spatial = rs.spatial_filter()\n",
    "spatial.set_option(rs.option.filter_magnitude, 3)\n",
    "spatial.set_option(rs.option.filter_smooth_alpha, 0.5)\n",
    "spatial.set_option(rs.option.filter_smooth_delta, 20)\n",
    "spatial.set_option(rs.option.holes_fill, 0)\n",
    "temporal = rs.temporal_filter()\n",
    "# decimation = rs.decimation_filter()\n",
    "# decimation.set_option(rs.option.filter_magnitude, 4)\n",
    "hole_filling = rs.hole_filling_filter()\n",
    "hole_filling.set_option(rs.option.holes_fill, 1)\n",
    "\n",
    "# Image directory \n",
    "directory = r'./outputs/'\n",
    "img_count = 1\n",
    "try:\n",
    "    while True:\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        ir1_frame = frames.get_infrared_frame(1) # Left IR Camera, it allows 0, 1 or no input\n",
    "        ir2_frame = frames.get_infrared_frame(2) # Right IR camera\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        if not ir1_frame or not ir2_frame:\n",
    "            continue\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data()) # dtype of print(depth_image.dtype) is: uint16\n",
    "        color_image = np.asanyarray(color_frame.get_data()) # dtype of print(color_image.dtype) is: uint8\n",
    "        ir1_image = np.asanyarray(ir1_frame.get_data())\n",
    "        ir2_image = np.asanyarray(ir2_frame.get_data())\n",
    "        \n",
    "        left = ir1_image\n",
    "        right = ir2_image\n",
    "        \n",
    "        rs_depth = depth_image # (image of 16-bit per pixel)\n",
    "        rs_depth_sccaled  = cv2.convertScaleAbs(depth_image, alpha=0.03)  # (image converted to 8-bit per pixel)\n",
    "        \n",
    "        ## Apply filters to real-sense depth\n",
    "        filtered_rs_depth = spatial.process(depth_frame)\n",
    "        filtered_rs_depth = temporal.process(filtered_rs_depth)\n",
    "        filtered_rs_depth = hole_filling.process(filtered_rs_depth)\n",
    "        \n",
    "        filtered_rs_depth = np.asanyarray(filtered_rs_depth.get_data()) # dtype of print(filtered_rs_depth.dtype) is: uint16\n",
    "        filtered_rs_depth_scaled = cv2.convertScaleAbs(filtered_rs_depth, alpha=0.03)  # (image converted to 8-bit per pixel)\n",
    "        \n",
    "        ## StereoBM Disparity and Depth Maps\n",
    "        raw_disparity, filtered_disparity = getDisparityMap(left, right, \"bm\")\n",
    "        \n",
    "        raw_depth_map, raw_valid_pixels = convertDisparityMapToDepthMap(raw_disparity)\n",
    "        filtered_depth_map, filtered_valid_pixels = convertDisparityMapToDepthMap(filtered_disparity)\n",
    "        \n",
    "        ## Use StereoNet to estimate depth\n",
    "        sn_depth_map, sn_disparity = getStereoNet(left, right)\n",
    "        \n",
    "        \n",
    "        #### VISUALISATION ####\n",
    "        is_visual_on = True\n",
    "        if not is_visual_on:\n",
    "            continue\n",
    "        \n",
    "        ## Visualize RGB frame\n",
    "#         cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "#         cv2.imshow('RealSense', color_image)\n",
    "        \n",
    "        ## Visualize IR frames\n",
    "        ir_images = np.hstack((ir1_image, ir2_image))\n",
    "        cv2.namedWindow('IRSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('IRSense', ir_images)\n",
    "        \n",
    "        ## Visualize Real sense depth frames\n",
    "        ## Apply colormap on Real-sense depth image \n",
    "        depth_colormap = cv2.applyColorMap(rs_depth_sccaled, cv2.COLORMAP_JET)\n",
    "        #depth_colormap = cv2.applyColorMap(cv2.equalizeHist(rs_depth_sccaled), cv2.COLORMAP_JET)\n",
    "        #filtered_depth_colormap = cv2.applyColorMap(filtered_rs_depth_scaled, cv2.COLORMAP_JET)\n",
    "        filtered_depth_colormap = cv2.applyColorMap(cv2.equalizeHist(filtered_rs_depth_scaled), cv2.COLORMAP_JET)\n",
    "        both_depths2 = np.hstack((depth_colormap, filtered_depth_colormap))\n",
    "        cv2.namedWindow('RS_DepthMap', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RS_DepthMap', both_depths2)\n",
    "        \n",
    "        \n",
    "        ## Visualize stereoNet disparity and depth maps (StereoNET)\n",
    "        o1 = cv2.applyColorMap(np.array(sn_disparity*2, dtype=np.uint8), cv2.COLORMAP_JET)\n",
    "        #o2 = cv2.applyColorMap(cv2.equalizeHist(sn_depth_map), cv2.COLORMAP_JET)\n",
    "        o2 = cv2.applyColorMap(sn_depth_map, cv2.COLORMAP_JET)\n",
    "#         o2[sn_depth_map < 0] = 0\n",
    "        #stn_images = o1\n",
    "        stn_images = np.hstack((o1, o2))\n",
    "        cv2.namedWindow('StereoNet', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('StereoNet', stn_images)\n",
    "\n",
    "#         ## Visualize disparity maps (stereobm)\n",
    "#         intensity_scale_factor = 6  # for visualizing strong intensity\n",
    "#         raw_disparity_scaled = cv2.convertScaleAbs(raw_disparity * intensity_scale_factor, alpha=0.03)\n",
    "#         filtered_disparity_scaled = cv2.convertScaleAbs(filtered_disparity * intensity_scale_factor, alpha=0.03)\n",
    "#         disparity_images = np.hstack((raw_disparity_scaled, filtered_disparity_scaled))\n",
    "#         cv2.namedWindow(\"Computed_Disparity\", cv2.WINDOW_AUTOSIZE);\n",
    "#         cv2.imshow(\"Computed_Disparity\", disparity_images);\n",
    "\n",
    "#         ## Visualize depth maps (stereobm)\n",
    "#         temp1 = cv2.applyColorMap(cv2.equalizeHist(raw_depth_map), cv2.COLORMAP_JET)\n",
    "#         temp1[~raw_valid_pixels] = 0\n",
    "        \n",
    "#         temp2 = cv2.applyColorMap(cv2.equalizeHist(filtered_depth_map), cv2.COLORMAP_JET)\n",
    "#         temp2[~filtered_valid_pixels] = 0\n",
    "        \n",
    "#         both_depths = np.hstack((temp1, temp2))\n",
    "        \n",
    "#         cv2.namedWindow(\"depth_maps\", cv2.WINDOW_AUTOSIZE);\n",
    "#         cv2.imshow(\"depth_maps\", both_depths);\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        # Press esc or 'q' to close the image window\n",
    "        if key & 0xFF == ord('q') or key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        if key == 116:\n",
    "            cv2.imwrite(directory + str(img_count) + '_color_image.jpg', color_image)\n",
    "            cv2.imwrite(directory + str(img_count) + '_left.jpg', left)\n",
    "            cv2.imwrite(directory + str(img_count) + '_right.jpg', right)\n",
    "            cv2.imwrite(directory + str(img_count) + '_rs_depth.jpg', depth_colormap)\n",
    "            cv2.imwrite(directory + str(img_count) + '_rs_filtered_depth.jpg', filtered_depth_colormap)\n",
    "            cv2.imwrite(directory + str(img_count) + '_bm_depth.jpg', temp1)\n",
    "            cv2.imwrite(directory + str(img_count) + '_bm_filtered_depth.jpg', temp2)\n",
    "            cv2.imwrite(directory + str(img_count) + '_bm_disparity.jpg', raw_disparity_scaled)\n",
    "            cv2.imwrite(directory + str(img_count) + '_bm_filtered_disparity.jpg', filtered_disparity_scaled)\n",
    "            img_count = img_count+1\n",
    "\n",
    "finally:\n",
    "\n",
    "    # Stop streaming\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Kinfu in python does not work to a memory issues in opencv implementation (https://github.com/opencv/opencv_contrib/issues/2607)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera intrinsics:\n",
      "[[643.338013   0.       638.95697 ]\n",
      " [  0.       643.096008 402.330017]\n",
      " [  0.         0.         1.      ]]\n"
     ]
    }
   ],
   "source": [
    "focal_length = 643.338013 #942.8       # lense focal length, 1.88mm, 942.8 ???  643.338013, 643.096008\n",
    "baseline = 55   #49.75  distance in mm between the two cameras\n",
    "units = 0.512     # depth units, adjusted for the output to fit in one byte\n",
    "\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "intrinsicsNp = np.array(\n",
    "    [[643.338013, 0, 638.95697 ],\n",
    "     [  0, 643.096008, 402.330017],\n",
    "     [  0, 0, 1.0 ]])\n",
    "\n",
    "## FocalLengthLeft: 643.338379 643.096497\n",
    "## PrincipalPointLeft: 638.957336 402.329956\n",
    "## PinholeCameraIntrinsic(width: int, height: int, fx: float, fy: float, cx: float, cy: float)\n",
    "pinhole_camera_intrinsic = o3d.camera.PinholeCameraIntrinsic(width, height, \n",
    "                                                             643.338013, 643.096008, \n",
    "                                                             638.956970, 402.330017);\n",
    "\n",
    "print('Camera intrinsics:')\n",
    "print(pinhole_camera_intrinsic.intrinsic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPointCloud(rgb_img, depth_image):\n",
    "    # expects color image to be 8-bits per pixel\n",
    "    # expects depth image to be 16-bits per pixel\n",
    "    \n",
    "    o3dColorImage1 = o3d.geometry.Image(rgb_img)\n",
    "    o3dDepthImage1 = o3d.geometry.Image(depth_image)\n",
    "\n",
    "    # Create an RGBD open3d Image\n",
    "    frame_rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(o3dColorImage1, o3dDepthImage1, \n",
    "                                                                          convert_rgb_to_intensity=False)\n",
    "\n",
    "    # Create Point cloud\n",
    "    framePC = o3d.geometry.PointCloud.create_from_rgbd_image(frame_rgbd_image, pinhole_camera_intrinsic)\n",
    "    \n",
    "    \n",
    "#   framePC = o3d.geometry.PointCloud.create_from_depth_image(o3dDepthImage1, pinhole_camera_intrinsic, \n",
    "#                                                                   depth_scale=1000.0)\n",
    "    \n",
    "    return framePC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.setUseOptimized(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 480)\n",
      "[[643.338     0.      638.957  ]\n",
      " [  0.      643.096   402.33002]\n",
      " [  0.        0.        1.     ]]\n",
      "5000.0\n",
      "7\n",
      "0.03999999910593033\n",
      "4.5\n",
      "3\n",
      "0.005859375\n"
     ]
    }
   ],
   "source": [
    "params = cv2.kinfu.Params_defaultParams();\n",
    "params.frameSize = (width, height)\n",
    "params.depthFactor = 5000.0\n",
    "params.intr = intrinsicsNp\n",
    "\n",
    "print(params.frameSize)\n",
    "print(params.intr)\n",
    "print(params.depthFactor)\n",
    "print(params.bilateral_kernel_size)\n",
    "print(params.bilateral_sigma_depth)\n",
    "print(params.bilateral_sigma_spatial)\n",
    "print(params.pyramidLevels)\n",
    "print(params.voxelSize)\n",
    "\n",
    "kinfu = cv2.kinfu.KinFu_create(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laser power =  150.0\n",
      "laser power range =  0.0 ~ 360.0\n",
      "True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'cv2.kinfu_KinFu' has no attribute 'getPose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e5a019d1738a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m#         out = np.zeros(shape=filtered_rs_depth.shape).astype(np.float32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mpose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkinfu_KinFu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;31m#         print(pose)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'cv2.kinfu_KinFu' has no attribute 'getPose'"
     ]
    }
   ],
   "source": [
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "res_x = width\n",
    "res_y = height\n",
    "\n",
    "config.enable_stream(rs.stream.depth, res_x, res_y, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, res_x, res_y, rs.format.bgr8, 30)\n",
    "\n",
    "config.enable_stream(rs.stream.infrared, 1, res_x, res_y, rs.format.y8, 30)\n",
    "config.enable_stream(rs.stream.infrared, 2, res_x, res_y, rs.format.y8, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline_profile = pipeline.start(config)\n",
    "\n",
    "## To set laser on/off or set laser power\n",
    "device = pipeline_profile.get_device()\n",
    "depth_sensor = device.query_sensors()[0]\n",
    "laser_pwr = depth_sensor.get_option(rs.option.laser_power)\n",
    "print(\"laser power = \", laser_pwr)\n",
    "laser_range = depth_sensor.get_option_range(rs.option.laser_power)\n",
    "print(\"laser power range = \" , laser_range.min , \"~\", laser_range.max)\n",
    "depth_sensor.set_option(rs.option.laser_power, 150)\n",
    "\n",
    "\n",
    "spatial = rs.spatial_filter()\n",
    "spatial.set_option(rs.option.filter_magnitude, 3)\n",
    "spatial.set_option(rs.option.filter_smooth_alpha, 0.5)\n",
    "spatial.set_option(rs.option.filter_smooth_delta, 20)\n",
    "spatial.set_option(rs.option.holes_fill, 0)\n",
    "temporal = rs.temporal_filter()\n",
    "# decimation = rs.decimation_filter()\n",
    "# decimation.set_option(rs.option.filter_magnitude, 4)\n",
    "hole_filling = rs.hole_filling_filter()\n",
    "hole_filling.set_option(rs.option.holes_fill, 1)\n",
    "\n",
    "# Image directory \n",
    "directory = r'./outputs/'\n",
    "img_count = 1\n",
    "\n",
    "# Reset Kinfu\n",
    "kinfu.reset()\n",
    "\n",
    "cc = 0\n",
    "try:\n",
    "    while True:\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        ir1_frame = frames.get_infrared_frame(1) # Left IR Camera, it allows 0, 1 or no input\n",
    "        ir2_frame = frames.get_infrared_frame(2) # Right IR camera\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "\n",
    "        if not ir1_frame or not ir2_frame:\n",
    "            continue\n",
    "            \n",
    "        # skipping first 20 frames, to wait for sensor for warm up\n",
    "        cc = cc + 1\n",
    "        if cc < 20:\n",
    "            continue\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        depth_image = np.asanyarray(depth_frame.get_data()) # dtype of print(depth_image.dtype) is: uint16\n",
    "        color_image = np.asanyarray(color_frame.get_data()) # FORMAT: BGR, dtype of print(color_image.dtype) is: uint8\n",
    "        color_image_rgb = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        ir1_image = np.asanyarray(ir1_frame.get_data()) # Left image\n",
    "        ir2_image = np.asanyarray(ir2_frame.get_data()) # Right image\n",
    "        \n",
    "        left = ir1_image\n",
    "        right = ir2_image\n",
    "        rs_depth = depth_image # (image of 16-bit per pixel)\n",
    "        \n",
    "        ## Apply filters to real-sense depth\n",
    "        filtered_rs_depth = spatial.process(depth_frame)\n",
    "        filtered_rs_depth = temporal.process(filtered_rs_depth)\n",
    "        filtered_rs_depth = hole_filling.process(filtered_rs_depth)\n",
    "        filtered_rs_depth = np.asanyarray(filtered_rs_depth.get_data()) # dtype of print(filtered_rs_depth.dtype) is: uint16\n",
    "        \n",
    "        ## Apply bilateral filter to RS depth image BEFORE RS filters\n",
    "        tmp = rs_depth.astype(np.float32)\n",
    "        tmp = cv2.bilateralFilter(tmp, 9, 75, 75)\n",
    "        bilateral_depth = tmp.astype(np.uint16)\n",
    "        \n",
    "        ## Apply bilateral filter to RS depth image AFTER RS filters\n",
    "        tmp = filtered_rs_depth.astype(np.float32)\n",
    "        tmp = cv2.bilateralFilter(tmp, 9, 75, 75)\n",
    "        filtered_bilateral_depth = tmp.astype(np.uint16)\n",
    "        \n",
    "        \n",
    "#         print('# of valid depth values [rs_depth]: ', len(rs_depth[rs_depth > 0]))\n",
    "#         print(rs_depth[rs_depth > 0])\n",
    "#         print('# of valid depth values [bilateral_depth]: ', len(bilateral_depth[bilateral_depth > 0]))\n",
    "#         print(bilateral_depth[bilateral_depth > 0])\n",
    "        \n",
    "#         print('# of valid depth values [filtered_rs_depth]: ', len(filtered_rs_depth[filtered_rs_depth > 0]))\n",
    "#         print(filtered_rs_depth[filtered_rs_depth > 0])\n",
    "#         print('# of valid depth values [filtered_bilateral_depth]: ', len(filtered_bilateral_depth[filtered_bilateral_depth > 0]))\n",
    "#         print(filtered_bilateral_depth[filtered_bilateral_depth > 0])\n",
    "        \n",
    "    \n",
    "        result = kinfu.update(filtered_rs_depth)\n",
    "        print(result)\n",
    "#         out = np.zeros(shape=filtered_rs_depth.shape).astype(np.float32)\n",
    "        pose = cv2.kinfu_KinFu.getPose()\n",
    "#         print(pose)\n",
    "\n",
    "\n",
    "                    \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "        #### VISUALISATION ####\n",
    "        is_visual_on = False\n",
    "        if not is_visual_on:\n",
    "            continue\n",
    "        \n",
    "        ## Visualize RGB frame\n",
    "#         cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "#         cv2.imshow('RealSense', color_image)\n",
    "        \n",
    "        ## Visualize IR frames\n",
    "        ir_images = np.hstack((ir1_image, ir2_image))\n",
    "        cv2.namedWindow('IRSense', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('IRSense', ir_images)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Visualize Real sense depth frames\n",
    "        ## Apply colormap on Real-sense depth image \n",
    "        rs_depth_sccaled  = cv2.convertScaleAbs(depth_image, alpha=0.03)  # (image converted to 8-bit per pixel)\n",
    "        filtered_rs_depth_scaled = cv2.convertScaleAbs(filtered_rs_depth, alpha=0.03)  # (image converted to 8-bit per pixel)\n",
    "        #depth_colormap = cv2.applyColorMap(rs_depth_sccaled, cv2.COLORMAP_JET)\n",
    "        depth_colormap = cv2.applyColorMap(cv2.equalizeHist(rs_depth_sccaled), cv2.COLORMAP_JET)\n",
    "        #filtered_depth_colormap = cv2.applyColorMap(filtered_rs_depth_scaled, cv2.COLORMAP_JET)\n",
    "        filtered_depth_colormap = cv2.applyColorMap(cv2.equalizeHist(filtered_rs_depth_scaled), cv2.COLORMAP_JET)\n",
    "        both_depths2 = np.hstack((depth_colormap, filtered_depth_colormap))\n",
    "        cv2.namedWindow('RS_DepthMap', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RS_DepthMap', both_depths2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Visualize Real sense depth frames with Bilateral filter\n",
    "        bilateral_depth_colormap = cv2.applyColorMap(cv2.equalizeHist(cv2.convertScaleAbs(bilateral_depth, alpha=0.03)), cv2.COLORMAP_JET)\n",
    "        bilateral_filtered_depth_colormap = cv2.applyColorMap(cv2.equalizeHist(cv2.convertScaleAbs(filtered_bilateral_depth, alpha=0.03)), cv2.COLORMAP_JET)\n",
    "        both_depths2 = np.hstack((bilateral_depth_colormap, bilateral_filtered_depth_colormap))\n",
    "        cv2.namedWindow('RS_Bilateral_DepthMap', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('RS_Bilateral_DepthMap', both_depths2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         ## Visualize RealSense refined disparity and depth maps\n",
    "        tmp1 = cv2.convertScaleAbs(refined_rs_disparity.astype(np.uint16))\n",
    "        o3 = cv2.applyColorMap(cv2.equalizeHist(tmp1), cv2.COLORMAP_JET)\n",
    "        o3[refined_rs_disparity < 0] = 0\n",
    "        o4 = cv2.applyColorMap(cv2.equalizeHist(cv2.convertScaleAbs(refined_rs_depth, alpha=0.03)), cv2.COLORMAP_JET)\n",
    "        o4[refined_rs_depth < 0] = 0\n",
    "        stn_images1 = np.hstack((o3, o4))\n",
    "        cv2.namedWindow('Refined', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('Refined', stn_images1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Visualize stereoNet disparity and depth maps (StereoNET)\n",
    "        tmp1 = cv2.convertScaleAbs(sn_disparity.astype(np.uint16))\n",
    "        o1 = cv2.applyColorMap(cv2.equalizeHist(tmp1), cv2.COLORMAP_JET)\n",
    "        o1[sn_disparity < 0] = 0\n",
    "        o2 = cv2.applyColorMap(cv2.equalizeHist(cv2.convertScaleAbs(sn_depth_map, alpha=0.03)), cv2.COLORMAP_JET)\n",
    "        o2[sn_depth_map < 0] = 0\n",
    "        #stn_images = o1\n",
    "        stn_images = np.hstack((o1, o2))\n",
    "        cv2.namedWindow('StereoNet', cv2.WINDOW_AUTOSIZE)\n",
    "        cv2.imshow('StereoNet', stn_images)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        # Press esc or 'q' to close the image window\n",
    "        if key & 0xFF == ord('q') or key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        if key == 116:\n",
    "#             cv2.imwrite(directory + str(img_count) + '_color_image.jpg', color_image)\n",
    "#             cv2.imwrite(directory + str(img_count) + '_left.jpg', left)\n",
    "#             cv2.imwrite(directory + str(img_count) + '_right.jpg', right)\n",
    "#             cv2.imwrite(directory + str(img_count) + '_rs_depth.jpg', depth_colormap)\n",
    "#             cv2.imwrite(directory + str(img_count) + '_rs_filtered_depth.jpg', filtered_depth_colormap)\n",
    "#             cv2.imwrite(directory + str(img_count) + '_bm_depth.jpg', temp1)\n",
    "#             cv2.imwrite(directory + str(img_count) + '_bm_filtered_depth.jpg', temp2)\n",
    "#             cv2.imwrite(directory + str(img_count) + '_bm_disparity.jpg', raw_disparity_scaled)\n",
    "#             cv2.imwrite(directory + str(img_count) + '_bm_filtered_disparity.jpg', filtered_disparity_scaled)\n",
    "            img_count = img_count+1\n",
    "        if key == ord('1'):\n",
    "            rs_pc = getPointCloud(color_image_rgb, rs_depth)\n",
    "            rs_pc.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "            print('rs_pc', rs_pc)\n",
    "            o3d.visualization.draw_geometries([rs_pc])\n",
    "        if key == ord('2'):\n",
    "            rs_pc = getPointCloud(color_image_rgb, filtered_rs_depth)\n",
    "            rs_pc.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "            print('rs_pc', rs_pc)\n",
    "            o3d.visualization.draw_geometries([rs_pc])\n",
    "        if key == ord('3'):\n",
    "            rs_pc = getPointCloud(color_image_rgb, bilateral_depth)\n",
    "            rs_pc.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "            print('rs_pc', rs_pc)\n",
    "            o3d.visualization.draw_geometries([rs_pc])\n",
    "        if key == ord('4'):\n",
    "            rs_pc = getPointCloud(color_image_rgb, sn_depth_map)\n",
    "            rs_pc.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "            print('rs_pc', rs_pc)\n",
    "            o3d.visualization.draw_geometries([rs_pc])\n",
    "        if key == ord('5'):\n",
    "            rs_pc = getPointCloud(color_image_rgb, refined_rs_depth)\n",
    "            rs_pc.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "            print('rs_pc', rs_pc)\n",
    "            o3d.visualization.draw_geometries([rs_pc])\n",
    "            \n",
    "finally:\n",
    "\n",
    "    # Stop streaming\n",
    "    pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
